{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d60cce7-82d6-4a74-bfaa-28f109e8ffff",
   "metadata": {},
   "source": [
    "# Homework 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e42a34-2444-4fe8-bf5e-b398b09e0c3f",
   "metadata": {},
   "source": [
    "## Option 1 - URL analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4538e-2a7c-431b-8abd-e215f4367cae",
   "metadata": {},
   "source": [
    "### Cell 1 – Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2728f3b-7c9b-49b1-aa50-3d7ec183a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import urlparse, parse_qsl\n",
    "import tldextract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe35d1-31c6-4ec5-9950-8db6698a9b4c",
   "metadata": {},
   "source": [
    "### Cell 2 – URL Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b633ac64-2385-4fea-af4e-06770c7b665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_url(url):\n",
    "    parsed = urlparse(url)\n",
    "    ext = tldextract.extract(url)\n",
    "\n",
    "    path = parsed.path\n",
    "    file_name = \"\"\n",
    "    if path and path != \"/\":\n",
    "        last_part = path.rstrip(\"/\").split(\"/\")[-1]\n",
    "        if \".\" in last_part:\n",
    "            file_name = last_part\n",
    "\n",
    "    return {\n",
    "        \"URL\": url,\n",
    "        \"Scheme\": parsed.scheme,\n",
    "        \"TLD\": ext.suffix,\n",
    "        \"Domain\": ext.domain,\n",
    "        \"Subdomain\": ext.subdomain,\n",
    "        \"Host\": parsed.netloc,\n",
    "        \"Port\": parsed.port,\n",
    "        \"Path\": path,\n",
    "        \"File Name\": file_name,\n",
    "        \"Query Parameters\": dict(parse_qsl(parsed.query))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d393cc-50fe-4036-a4f2-efb96f075e08",
   "metadata": {},
   "source": [
    "### Cell 3 – robots.txt Fetching and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a484114-4e50-4744-aa4e-fcb7efe7da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_robots(base_url):\n",
    "    robots_url = base_url.rstrip(\"/\") + \"/robots.txt\"\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            robots_url,\n",
    "            headers={\"User-Agent\": \"Mozilla/5.0\"},\n",
    "            timeout=10\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_robots(text):\n",
    "    user_agents = set()\n",
    "    disallow = []\n",
    "    crawl_delays = []\n",
    "\n",
    "    current_agents = []\n",
    "\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "\n",
    "        if \":\" not in line:\n",
    "            continue\n",
    "\n",
    "        key, value = line.split(\":\", 1)\n",
    "        key = key.lower().strip()\n",
    "        value = value.strip()\n",
    "\n",
    "        if key == \"user-agent\":\n",
    "            current_agents = [value]\n",
    "            user_agents.add(value)\n",
    "\n",
    "        elif key == \"disallow\" and value:\n",
    "            disallow.append(value)\n",
    "\n",
    "        elif key == \"crawl-delay\":\n",
    "            try:\n",
    "                crawl_delays.append(float(value))\n",
    "            except:\n",
    "                crawl_delays.append(value)\n",
    "\n",
    "    return {\n",
    "        \"User-Agents\": sorted(user_agents),\n",
    "        \"Disallowed Paths\": disallow,\n",
    "        \"Crawl-Delay\": crawl_delays\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79318496-ef8e-472a-ab44-d0e3e9992871",
   "metadata": {},
   "source": [
    "### Cell 4 – Run Analysis on All URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac9bb24d-e8a9-46b1-816e-df861277b7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Scheme</th>\n",
       "      <th>TLD</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Subdomain</th>\n",
       "      <th>Host</th>\n",
       "      <th>Port</th>\n",
       "      <th>Path</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Query Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://edition.cnn.com/2025/12/22/media/60-mi...</td>\n",
       "      <td>https</td>\n",
       "      <td>com</td>\n",
       "      <td>cnn</td>\n",
       "      <td>edition</td>\n",
       "      <td>edition.cnn.com</td>\n",
       "      <td>None</td>\n",
       "      <td>/2025/12/22/media/60-minutes-cecot-bari-weiss-...</td>\n",
       "      <td></td>\n",
       "      <td>{'iid': 'cnn_buildContentRecirc_end_recirc', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.nhm.ac.uk/visit/exhibitions/wildli...</td>\n",
       "      <td>https</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>nhm</td>\n",
       "      <td>www</td>\n",
       "      <td>www.nhm.ac.uk</td>\n",
       "      <td>None</td>\n",
       "      <td>/visit/exhibitions/wildlife-photographer-of-th...</td>\n",
       "      <td>wildlife-photographer-of-the-year.html</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://is-web.hevra.haifa.ac.il/images/2025_S...</td>\n",
       "      <td>https</td>\n",
       "      <td>ac.il</td>\n",
       "      <td>haifa</td>\n",
       "      <td>is-web.hevra</td>\n",
       "      <td>is-web.hevra.haifa.ac.il</td>\n",
       "      <td>None</td>\n",
       "      <td>/images/2025_SEM._aa.pdf</td>\n",
       "      <td>2025_SEM._aa.pdf</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL Scheme    TLD Domain  \\\n",
       "0  https://edition.cnn.com/2025/12/22/media/60-mi...  https    com    cnn   \n",
       "1  https://www.nhm.ac.uk/visit/exhibitions/wildli...  https  ac.uk    nhm   \n",
       "2  https://is-web.hevra.haifa.ac.il/images/2025_S...  https  ac.il  haifa   \n",
       "\n",
       "      Subdomain                      Host  Port  \\\n",
       "0       edition           edition.cnn.com  None   \n",
       "1           www             www.nhm.ac.uk  None   \n",
       "2  is-web.hevra  is-web.hevra.haifa.ac.il  None   \n",
       "\n",
       "                                                Path  \\\n",
       "0  /2025/12/22/media/60-minutes-cecot-bari-weiss-...   \n",
       "1  /visit/exhibitions/wildlife-photographer-of-th...   \n",
       "2                           /images/2025_SEM._aa.pdf   \n",
       "\n",
       "                                File Name  \\\n",
       "0                                           \n",
       "1  wildlife-photographer-of-the-year.html   \n",
       "2                        2025_SEM._aa.pdf   \n",
       "\n",
       "                                    Query Parameters  \n",
       "0  {'iid': 'cnn_buildContentRecirc_end_recirc', '...  \n",
       "1                                                 {}  \n",
       "2                                                 {}  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://edition.cnn.com/2025/12/22/media/60-minutes-cecot-bari-weiss-canada-global-tv?iid=cnn_buildContentRecirc_end_recirc&recs_exp=most-popular-article-end&tenant_id=popular.en\",\n",
    "    \"https://www.nhm.ac.uk/visit/exhibitions/wildlife-photographer-of-the-year.html\",\n",
    "    \"https://is-web.hevra.haifa.ac.il/images/2025_SEM._aa.pdf\"\n",
    "]\n",
    "\n",
    "url_results = []\n",
    "robots_results = []\n",
    "\n",
    "for url in urls:\n",
    "    info = analyze_url(url)\n",
    "    url_results.append(info)\n",
    "\n",
    "    base = f\"{info['Scheme']}://{info['Host']}\"\n",
    "    robots_text = fetch_robots(base)\n",
    "\n",
    "    if robots_text:\n",
    "        parsed = parse_robots(robots_text)\n",
    "        robots_results.append({\n",
    "            \"Host\": base,\n",
    "            \"robots.txt Exists\": True,\n",
    "            \"User-Agents\": parsed[\"User-Agents\"],\n",
    "            \"Disallowed URLs\": [base + p for p in parsed[\"Disallowed Paths\"]],\n",
    "            \"Crawl-Delay\": parsed[\"Crawl-Delay\"]\n",
    "        })\n",
    "    else:\n",
    "        robots_results.append({\n",
    "            \"Host\": base,\n",
    "            \"robots.txt Exists\": False,\n",
    "            \"User-Agents\": [],\n",
    "            \"Disallowed URLs\": [],\n",
    "            \"Crawl-Delay\": []\n",
    "        })\n",
    "\n",
    "df_urls = pd.DataFrame(url_results)\n",
    "df_robots = pd.DataFrame(robots_results)\n",
    "\n",
    "df_urls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aded31b-ff08-47d0-b135-b3c8fb5023cf",
   "metadata": {},
   "source": [
    "### Cell 5 – robots.txt Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9570f6e-770f-4f6e-8b59-2016a2fcd6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host</th>\n",
       "      <th>robots.txt Exists</th>\n",
       "      <th>User-Agents</th>\n",
       "      <th>Disallowed URLs</th>\n",
       "      <th>Crawl-Delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://edition.cnn.com</td>\n",
       "      <td>True</td>\n",
       "      <td>[*, AI2Bot, Ai2Bot-Dolma, Amazonbot, Applebot-...</td>\n",
       "      <td>[https://edition.cnn.com/, https://edition.cnn...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.nhm.ac.uk</td>\n",
       "      <td>True</td>\n",
       "      <td>[*]</td>\n",
       "      <td>[https://www.nhm.ac.uk/uksf-bin/, https://www....</td>\n",
       "      <td>[8.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://is-web.hevra.haifa.ac.il</td>\n",
       "      <td>True</td>\n",
       "      <td>[*]</td>\n",
       "      <td>[https://is-web.hevra.haifa.ac.il/administrato...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Host  robots.txt Exists  \\\n",
       "0           https://edition.cnn.com               True   \n",
       "1             https://www.nhm.ac.uk               True   \n",
       "2  https://is-web.hevra.haifa.ac.il               True   \n",
       "\n",
       "                                         User-Agents  \\\n",
       "0  [*, AI2Bot, Ai2Bot-Dolma, Amazonbot, Applebot-...   \n",
       "1                                                [*]   \n",
       "2                                                [*]   \n",
       "\n",
       "                                     Disallowed URLs Crawl-Delay  \n",
       "0  [https://edition.cnn.com/, https://edition.cnn...          []  \n",
       "1  [https://www.nhm.ac.uk/uksf-bin/, https://www....       [8.0]  \n",
       "2  [https://is-web.hevra.haifa.ac.il/administrato...          []  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_robots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd82568-0161-4451-aeb3-7a1f4157ec59",
   "metadata": {},
   "source": [
    "## Summary – URL Analysis & Robots.txt\n",
    "\n",
    "In this task, we implemented **Option 1: URL Analysis**.  \n",
    "Each given URL was parsed and decomposed into its standard components, including **scheme, TLD, domain, subdomain, host, port, path, file name, and query parameters**.  \n",
    "The extracted information was presented in a structured **DataFrame** for clarity and analysis.\n",
    "\n",
    "In addition, we checked the existence of a **robots.txt** file for each URL host to ensure polite and responsible crawling behavior.  \n",
    "When a robots.txt file was found, we extracted the **User-Agent rules**, the list of **disallowed paths (converted to full URLs)**, and the **crawl-delay** directive when available.\n",
    "\n",
    "The results demonstrate correct understanding of URL structure and adherence to web crawling best practices, with all findings clearly summarized in tabular form.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
